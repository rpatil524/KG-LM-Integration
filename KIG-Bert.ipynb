{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f5d47c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415ab001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "import gc\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from models.models import *\n",
    "\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModel\n",
    "from transformers.activations import GELUActivation\n",
    "from transformers.modeling_outputs import MaskedLMOutput\n",
    "from transformers import DataCollatorForWholeWordMask\n",
    "from datasets import load_from_disk, load_dataset\n",
    "from transformers import BertTokenizer, DistilBertTokenizer\n",
    "from transformers.data.data_collator import _torch_collate_batch\n",
    "import evaluate\n",
    "\n",
    "import wandb\n",
    "# wandb.init(project=\"kg-lm-integration\", entity=\"tanny411\")\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "#notebook_login()\n",
    "#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\n",
    "emb_tsv_file = \"wikidata_translation_v1.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d2eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.getrecursionlimit())\n",
    "\n",
    "sys.setrecursionlimit(100000)\n",
    "# but doing so is dangerous -- the standard limit is a little conservative, but Python stackframes can be quite big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed5a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available(), torch.cuda.device_count(), torch.cuda.current_device(), torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1447d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = \"distilbert-base-uncased\" ##\"bert-base-cased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc6a6ac",
   "metadata": {},
   "source": [
    "# Initialize Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d8ed2b",
   "metadata": {},
   "source": [
    "Download:\n",
    "- embeds_wktxt.csv\n",
    "- [linked-wikitext-2 dataset](https://rloganiv.github.io/linked-wikitext-2/#/) and unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b41ccbd",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8495d87e",
   "metadata": {},
   "source": [
    "- `tokens` are the given list of tokens from wikitext2\n",
    "- `input_ids` are what come from tokenization, they divide certain words into multiple pieces, and each sentence has a CLS and a SEP\n",
    "- `word_tokens` is the length of `tokens`. For each token in `token`, it mentions how many sub-words it was divided into due to word piece tokenization\n",
    "- `cummulative_word_tokens` is a cummulative sum of `word_tokens`, with an extra 0 in the beginning\n",
    "\n",
    "##### Process\n",
    "index of a token in `token` can be found in `input_ids` by `cummulative_word_tokens`. if `ix` is the index of a word in `token`, its beginning index in `input_ids` is `cummulative_word_tokens[ix] + 1`, the +1 is because `input_ids` has a CLS in the beginning. `token[ix]` spans from `input_ids[cummulative_word_tokens[ix] + 1]` to `input_ids[cummulative_word_tokens[ix+1] + 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efb55fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds_wktxt = pd.read_csv(\"embeds_wktxt.csv\")\n",
    "qids_wktxt = pd.read_csv(\"qids_wktxt2.csv\")\n",
    "\n",
    "linked_wikitext_2 = \"linked-wikitext-2/\"\n",
    "train = linked_wikitext_2+\"train.jsonl\"\n",
    "valid = linked_wikitext_2+\"valid.jsonl\"\n",
    "test = linked_wikitext_2+\"test.jsonl\"\n",
    "\n",
    "data_files = {\"train\": train, \"valid\": valid, \"test\": test}\n",
    "wikitest2_dataset = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "chunk_size = 128\n",
    "\n",
    "class BertTokenizerModified(DistilBertTokenizer): #BertTokenizer\n",
    "    def __init__(self,vocab_file,**kwargs):\n",
    "        \n",
    "        super().__init__(vocab_file, never_split=[\"@@START@@\", \"@@END@@\", \"@@start@@\", \"@@end@@\"], **kwargs)\n",
    "    \n",
    "        self.tokenized_list = []\n",
    "\n",
    "    def _tokenize(self, text):\n",
    "        token_list = text.split()\n",
    "        split_tokens = []\n",
    "        tokenized_list = []\n",
    "        \n",
    "        if self.do_basic_tokenize:\n",
    "            for token in token_list:\n",
    "\n",
    "                # If the token is part of the never_split set\n",
    "                if token in self.basic_tokenizer.never_split:\n",
    "                    split_tokens.append(token)\n",
    "                    tokenized_list.append(1)\n",
    "                else:\n",
    "                    word_tokenized = self.wordpiece_tokenizer.tokenize(token)\n",
    "                    split_tokens += word_tokenized\n",
    "                    tokenized_list.append(len(word_tokenized))\n",
    "\n",
    "        self.tokenized_list.append(tokenized_list)\n",
    "        return split_tokens\n",
    "    \n",
    "def get_cumm(vals):\n",
    "    cumm = 0\n",
    "    res = [0] ## len of res is 1 more than vals, with an initial 0\n",
    "    for val in vals:\n",
    "        cumm += val\n",
    "        res.append(cumm)\n",
    "    return res\n",
    "\n",
    "def my_tokenize_function(data):\n",
    "    \n",
    "    ## tokenize\n",
    "    my_tokenizer.tokenized_list = []\n",
    "    result = my_tokenizer([\" \".join(eg) for eg in data[\"tokens\"]])\n",
    "    if my_tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    \n",
    "    ## save word to token mapping\n",
    "    ## 3, 1, 1 means the first word got divided into 3 tokens, the next into 1, and the next into 1 again\n",
    "    result[\"word_tokens\"] = my_tokenizer.tokenized_list\n",
    "    result[\"cummulative_word_tokens\"] = [get_cumm(x) for x in result[\"word_tokens\"]]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_kg_embedding_batched(data):\n",
    "    \n",
    "    ## store a masking array that says whether or not an item has kg embedding\n",
    "    \"\"\"\n",
    "    When you specify batched=True the function receives a dictionary with the fields of the dataset, \n",
    "    but each value is now a list of values, and not just a single value. \n",
    "    \"\"\"\n",
    "    input_ids_list = data[\"input_ids\"]\n",
    "    annotations_list = data['annotations']\n",
    "    cummulative_word_tokens_list = data[\"cummulative_word_tokens\"]\n",
    "    \n",
    "    batch_size = len(input_ids_list)\n",
    "    embed_list = [] ## len will be batch_size\n",
    "    embed_mask = []\n",
    "    embed_mask_qid = []\n",
    "    \n",
    "    #add by Edward, the index of qid\n",
    "    embed_mask_index = []\n",
    "    \n",
    "    allc = 0\n",
    "    cc = 0\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        input_ids = input_ids_list[i]\n",
    "        annotations = annotations_list[i]\n",
    "        \n",
    "        ## Replace zeros with random numbers if required\n",
    "        embeds = np.zeros((len(input_ids), 200)) ## CLS, SEP will have np.zeros, like unknown words\n",
    "        mask = [0]*len(input_ids)\n",
    "        mask_qid = ['0']*len(input_ids)\n",
    "        \n",
    "        #add by Edward\n",
    "        mask_index = [-100]*len(input_ids)\n",
    "        \n",
    "        \n",
    "        for annot in annotations:\n",
    "            start_ix, end_ix = annot['span']\n",
    "            start = cummulative_word_tokens_list[i][start_ix] + 1\n",
    "            end = cummulative_word_tokens_list[i][end_ix] + 1\n",
    "            \n",
    "            qid = annot['id']\n",
    "            \n",
    "            #add by Edward\n",
    "            index_list = qids_wktxt[qids_wktxt[\"id\"]==qid].index.tolist()\n",
    "            allc += 1\n",
    "            if len(index_list) == 0:\n",
    "                qid_index = -100\n",
    "\n",
    "            else:\n",
    "                qid_index = index_list[0]\n",
    "                cc+=1\n",
    "            \n",
    "            df = embeds_wktxt[embeds_wktxt['id']==qid]\n",
    "            if len(df)>0:\n",
    "                embeds[start:end] = np.tile(df.iloc[0,1:].values.reshape((1,200)),(end-start, 1))\n",
    "                mask[start:end] = [1]*(end-start)\n",
    "                mask_qid[start:end] = [qid]*(end-start)\n",
    "                \n",
    "                #add by Edward\n",
    "                mask_index[start:end] = [qid_index]*(end-start)\n",
    "                \n",
    "                \n",
    "        embed_mask.append(mask)\n",
    "        embed_mask_qid.append(mask_qid)\n",
    "        embed_list.append(embeds)\n",
    "        \n",
    "        #add by Edward\n",
    "        embed_mask_index.append(mask_index)\n",
    "\n",
    "    \n",
    "    print(cc/allc)\n",
    "    print(cc)\n",
    "    print(allc)\n",
    "    return {\n",
    "        \"kg_embedding\": embed_list, \n",
    "        \"kg_embedding_mask\": embed_mask,\n",
    "        \"kg_embedding_mask_qid\": embed_mask_qid,\n",
    "        \"kg_embedding_mask_index\": embed_mask_index\n",
    "    }\n",
    "\n",
    "def filter_text_batched(data):\n",
    "    \n",
    "    new_data = {k:[] for k in data}\n",
    "    \n",
    "    input_ids_list = data[\"input_ids\"]\n",
    "    \n",
    "    ## remove [UNK] == 100 \n",
    "    indices_list = [[i for i,input_id in enumerate(input_ids) if input_id!=100]\n",
    "                        for input_ids in input_ids_list]\n",
    "    \n",
    "    for k in data:\n",
    "        for indices, data_list in zip(indices_list, data[k]):\n",
    "            new_data[k].append([data_list[ind] for ind in indices])\n",
    "        \n",
    "    return new_data\n",
    "\n",
    "def truncate_data(data):\n",
    "    maxlength = my_tokenizer.max_model_input_sizes[bert_model_name]\n",
    "\n",
    "    ## truncate to maxlength\n",
    "    for k in data:\n",
    "        data[k] = [x[:maxlength] for x in data[k]]\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    # Compute length of concatenated texts\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the last chunk if it's smaller than chunk_size\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # Split by chunks of max_len\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    \n",
    "    # Create a new labels column\n",
    "#     result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae3812",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tokenizer = BertTokenizerModified.from_pretrained(bert_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc596d6",
   "metadata": {},
   "source": [
    "# Data processing and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538eaf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Linked Wikitext dataset\n",
    "dataset_file = \"concat_dataset_v2\"\n",
    "\n",
    "\n",
    "final_dataset = wikitest2_dataset.map(my_tokenize_function, batched=True)\\\n",
    "                          .map(get_kg_embedding_batched, batched=True, batch_size=100, keep_in_memory=False)\\\n",
    "                          .remove_columns(['title', 'tokens', 'annotations', 'word_tokens', 'cummulative_word_tokens'])\\\n",
    "                          .map(filter_text_batched, batched=True, batch_size=100, keep_in_memory=False)\\\n",
    "                          .map(group_texts, batched=True, batch_size=100, keep_in_memory=False)\\\n",
    "\n",
    "final_dataset.save_to_disk(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d1ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikidata fact dataset\n",
    "synthetic_data = \"generate_test_data/sythetic_dataset.jsonl\"\n",
    "synthetic_dataset = load_dataset(\"json\", data_files={\"synthetic\": synthetic_data})\n",
    "\n",
    "dataset_file = \"tokenized_synthetic_dataset_1\"\n",
    "\n",
    "tokenized_synthetic_dataset = synthetic_dataset.map(my_tokenize_function, batched=True)\\\n",
    "                          .map(get_kg_embedding_batched, batched=True, batch_size=100, keep_in_memory=False)\\\n",
    "                          .remove_columns(['title', 'tokens', 'annotations', 'word_tokens', 'cummulative_word_tokens'])\\\n",
    "\n",
    "tokenized_synthetic_dataset.save_to_disk(dataset_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae5e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the saved tokenized dataset\n",
    "dataset_file = \"concat_dataset_v2\"\n",
    "final_dataset = load_from_disk(dataset_file)\n",
    "\n",
    "dataset_file = \"tokenized_synthetic_dataset_1\"\n",
    "tokenized_synthetic_dataset = load_from_disk(dataset_file)\n",
    "\n",
    "\n",
    "# # To test model with smaller sample dataset\n",
    "train_size = 100\n",
    "test_size = 300\n",
    "downsampled_dataset = final_dataset[\"valid\"].train_test_split(train_size=train_size, test_size=test_size, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832fa9e0",
   "metadata": {},
   "source": [
    "## Create Data Collator for Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2314fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Create Data Collator for Masking\n",
    "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n",
    "from collections.abc import Mapping    \n",
    "    \n",
    "# NEW FOR EXTRA TEST    \n",
    "class CustomDataCollator(DataCollatorForWholeWordMask):\n",
    "    def torch_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n",
    "        if isinstance(examples[0], Mapping):\n",
    "            input_ids = [e[\"input_ids\"] for e in examples]\n",
    "            kg_embedding_mask = [e[\"kg_embedding_mask\"] for e in examples]\n",
    "            kg_embedding = [e[\"kg_embedding\"] for e in examples]\n",
    "            kg_embedding_mask_qid = [e[\"kg_embedding_mask_qid\"] for e in examples]\n",
    "            kg_embedding_mask_index = [e[\"kg_embedding_mask_index\"] for e in examples]\n",
    "        else:\n",
    "            raise Exception(\"Dataset needs to be in dictionary format\")\n",
    " \n",
    "        batch_input = _torch_collate_batch(input_ids, self.tokenizer, pad_to_multiple_of=self.pad_to_multiple_of)\n",
    " \n",
    "        mask_labels = kg_embedding_mask\n",
    "        batch_mask = _torch_collate_batch(kg_embedding_mask, self.tokenizer, pad_to_multiple_of=self.pad_to_multiple_of)\n",
    "        inputs, labels = self.torch_mask_tokens(batch_input, batch_mask)\n",
    " \n",
    "        batch_size = len(kg_embedding)\n",
    "        token_length = len(inputs[0])\n",
    "        embedding_size = len(kg_embedding[0][0])\n",
    " \n",
    "        kg_embedding = [kg_embds+[[0]*embedding_size]*(token_length-len(kg_embds)) for kg_embds in kg_embedding]\n",
    "    \n",
    "        batch_mask_index = _torch_collate_batch(kg_embedding_mask_index, self.tokenizer, pad_to_multiple_of=self.pad_to_multiple_of)\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "        return {\n",
    "                \"input_ids\": inputs, \n",
    "                \"labels\": labels, \n",
    "                \"kg_embedding\":kg_embedding, \n",
    "                \"kg_embedding_mask\": batch_mask,\n",
    "                \"kg_embedding_mask_qid\": [qid+['0']*(token_length-len(qid)) for qid in kg_embedding_mask_qid],\n",
    "                \"kg_embedding_mask_index\":batch_mask_index,\n",
    "               }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166a7e57",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197447bd",
   "metadata": {},
   "source": [
    "1. The KIM designed in this study is BERTModified. \n",
    "2. The basiline LM-Raw is BERTModified_LMRaw.\n",
    "3. The basiline KG-Raw is BERTModified_KGRaw.\n",
    "4. The alternative integration module Alt-KIM is BERTModified_alt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2e8e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"Our KIM\"  # or LM-Raw, KG-Raw, alt-KIM\n",
    "\n",
    "model_dict ={\"Our KIM\":BERTModified, \"LM-Raw\":BERTModified_LMRaw, \"KG-Raw\":BERTModified_KGRaw,\"alt-KIM\":BERTModified_alt}\n",
    "\n",
    "base_model = AutoModel.from_pretrained(bert_model_name)\n",
    "\n",
    "\n",
    "\n",
    "# choose the model needsto be trained \n",
    "model = model_dict[model_name](bert_model_name = bert_model_name,\n",
    "                                  base_model = base_model,\n",
    "                                  config = base_model.config, kg_size =46685)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e30fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data_collator\n",
    "data_collator = CustomDataCollator(tokenizer=my_tokenizer, mlm=True, mlm_probability=0.15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b0cc4f",
   "metadata": {},
   "source": [
    "# Evaluation metrics and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c77502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# metrics = evaluate.combine([\"accuracy\", \"precision\", \"recall\", \"f1\"])\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_preds=None, logits=None, labels=None):\n",
    "    \n",
    "    # We should have either `eval_preds` or both `logits` and `labels`\n",
    "    if eval_preds:\n",
    "        logits, labels = eval_preds\n",
    "\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[l for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [p for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    ## Flatten values\n",
    "    true_labels = [item for sublist in true_labels for item in sublist]\n",
    "    true_predictions = [item for sublist in true_predictions for item in sublist]\n",
    "    \n",
    "    accuracy = accuracy_metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    precision = precision_metric.compute(predictions=true_predictions, references=true_labels, average=\"micro\")\n",
    "    recall = recall_metric.compute(predictions=true_predictions, references=true_labels, average=\"micro\")\n",
    "    f1 = f1_metric.compute(predictions=true_predictions, references=true_labels, average=\"micro\")\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"],\n",
    "        \"f1\": f1[\"f1\"],\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f868c8e",
   "metadata": {},
   "source": [
    "# Create Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d2d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(final_dataset['train']) // batch_size #len(final_dataset['train']) // batch_size\n",
    "model_name = \"BERTModified\"\n",
    "output_dir = f\"{model_name}-finetuned-wikitext-test\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    push_to_hub=True,\n",
    "#     fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    "    num_train_epochs=50,\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model=\"loss\",#metric_name,\n",
    "#     greater_is_better = False,\n",
    "    logging_dir='logs',\n",
    "    report_to=\"wandb\",\n",
    "#     no_cuda=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ed9ae",
   "metadata": {},
   "source": [
    "metric_for_best_model (str, optional) — Use in conjunction with load_best_model_at_end to specify the metric to use to compare two different models. Must be the name of a metric returned by the evaluation with or without the prefix \"eval_\". Will default to \"loss\" if unspecified and load_best_model_at_end=True (to use the evaluation loss).\n",
    "\n",
    "If you set this value, greater_is_better will default to True. Don’t forget to set it to False if your metric is better when lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd221993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=downsampled_dataset[\"test\"],\n",
    "    train_dataset=final_dataset[\"train\"],\n",
    "    #eval_dataset=final_dataset[\"valid\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a5f89c",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cfd7d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "\n",
    "# training froma checkpoint\n",
    "\n",
    "# trainer.train(\"./BERTModified-fullsize-kg-finetuned-wikitext-test/checkpoint-65730\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4ed6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# basic evluation on perplexity \n",
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\") #21596 for 1 epoch\n",
    "\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cd9be2",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d68f90",
   "metadata": {},
   "source": [
    "## 1.LM-accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0283664",
   "metadata": {},
   "source": [
    "### 1.1 Linked Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2e81f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#predictions = trainer.predict(downsampled_dataset[\"test\"])\n",
    "predictions = trainer.predict(final_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337f585e",
   "metadata": {},
   "source": [
    "[About micro, macro, weighted precision, recall, f1 for multiclass labels](https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1)\n",
    "\n",
    "The following always holds true for the micro-F1 case:\n",
    "\n",
    "`micro-F1 = micro-precision = micro-recall = accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de842903",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show the result\n",
    "ompute_metrics(logits = predictions.predictions, labels = predictions.label_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a678c741",
   "metadata": {},
   "source": [
    "### 1.2 Wikidata facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f756533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(tokenized_synthetic_dataset[\"synthetic\"])\n",
    "\n",
    "compute_metrics(logits = predictions.predictions, labels = predictions.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c93337",
   "metadata": {},
   "source": [
    "## 2.KG-accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1729b7f3",
   "metadata": {},
   "source": [
    "### 2.1 Linked Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a51cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model_name = \"Our KIM\"\n",
    "model_dict_kg ={\"Our KIM\":BERTModified_KG, \"KG-Raw\":BERTModified_KGRaw,\"alt-KIM\":BERTModified_altKG}\n",
    "\n",
    "base_model = AutoModel.from_pretrained(bert_model_name)\n",
    "\n",
    "# choose the model needsto be trained \n",
    "model = model_dict_kg[model_name](bert_model_name = bert_model_name,\n",
    "                                  base_model = base_model,\n",
    "                                  config = base_model.config,kg_size =46685)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1249ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = torch.load(\"./\" + output_dir + \"/pytorch_model.bin\")\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74eff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    #eval_dataset=downsampled_dataset[\"test\"],\n",
    "    train_dataset=final_dataset[\"train\"],\n",
    "    eval_dataset=final_dataset[\"valid\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b6a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = trainer.predict(downsampled_dataset[\"test\"]) \n",
    "predictions = trainer.predict(final_dataset[\"test\"]) \n",
    "#labels = np.array(downsampled_dataset[\"test\"][\"kg_embedding_mask_index\"])\n",
    "labels = np.array(final_dataset[\"test\"][\"kg_embedding_mask_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbbe8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# show the result\n",
    "compute_metrics(logits = predictions.predictions, labels =labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be989d04",
   "metadata": {},
   "source": [
    "### 2.2 Wikidata facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a73418",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(tokenized_synthetic_dataset[\"synthetic\"])\n",
    "# true label of entitles\n",
    "labels = np.array(tokenized_synthetic_dataset[\"synthetic\"][\"kg_embedding_mask_index\"])\n",
    "\n",
    "# show the result\n",
    "compute_metrics(logits = predictions.predictions, labels =labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf6883f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
